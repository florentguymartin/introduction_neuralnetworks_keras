{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# ONE FIRST NEEDS TO RUN THIS CELL BEFORE LAUNCHING RISE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "plt.rc('axes', titlesize='xx-large')\n",
    "plt.rc('axes', labelsize='xx-large') \n",
    "plt.rc('legend', fontsize='x-large')\n",
    "plt.rc('xtick',labelsize='x-large')\n",
    "plt.rc('ytick',labelsize='x-large')\n",
    "plt.rc('lines',linewidth=4)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "np.random.seed(0)\n",
    "np.set_printoptions(suppress=True, precision=2)\n",
    "\n",
    "from keras import regularizers, optimizers\n",
    "from keras.utils.vis_utils import plot_model, model_to_dot\n",
    "from IPython.display import SVG\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('../data/acc_grid', 'rb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    acc_grid =pickle.load(f)\n",
    "    \n",
    "with open('../data/loss_grid', 'rb') as f:\n",
    "    loss_grid =pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# An introduction to neural networks with Keras\n",
    "Dr. Florent Martin (Universit√§t Regensburg)  \n",
    "March 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Machine Learning**\n",
    "* choose a **MODEL** which depends on **PARAMETERS**\n",
    "*  learn from **DATA**\n",
    "* choose model parameters that **FIT** the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Neural Networks**  =  family of models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Keras** = Python Library for Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img style=\"height:600px;margin: -5px 0px 0px 100px\" src=\"../figures/img/table1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. Logistic Regression\n",
    "  1. Iris Dataset\n",
    "  3. Logistic Regression with scikit-learn\n",
    "  4. Logistic Regression with Keras\n",
    "1. Gradient descent \n",
    "  1. Optimization\n",
    "  2. Loss function\n",
    "1. Neural Networks\n",
    "  2. Logistic Regression again\n",
    "  3. Neural Networks with hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Part 1  \n",
    "# Before Neural Networks: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1.1. Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "iris  = sns.load_dataset(\"iris\")\n",
    "iris.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "iris.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "iris.species.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><font size=7>Setosa</font></center> | <center><font size=7>**Versicolor**</font></center> | <center><font size=7> **Virginica** </font></center>\n",
    "---|---|---\n",
    "![setosa](../figures/img/setosa.jpg) | ![setosa](../figures/img/versicolor.jpg) | ![setosa](../figures/img/virginica.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(iris , hue=\"species\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Goal: knowing the petal width, predict if the iris is a virginica  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Input** = petal width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Question**: Is the iris sample a virginica?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Output** =  False / True (equivalently 0 / 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "iris['isVirginica'] = (iris['species'] == 'virginica').astype(int)\n",
    "iris.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots( figsize=(12,7) )\n",
    "iris.groupby('isVirginica').hist( column='petal_width' , ax = ax , bins=15 )\n",
    "plt.legend( [ 'not virginca' , 'virginica' ] )\n",
    "plt.xlabel('petal width')\n",
    "plt.ylabel('number of samples')\n",
    "plt.title('');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Is the plant a virginica?\n",
    "![guess the probabilities](../figures/img/probas1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Is the plant a virginica?\n",
    "![guess the probabilities](../figures/img/probas2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Is the plant a virginica?\n",
    "![guess the probabilities](../figures/img/probas3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<font size=6>\n",
    "**Logistic Regression** returns a function \n",
    "<br><br>\n",
    "$$ P: [0,3] \\to [0,1]$$\n",
    "</font>\n",
    "* $x = $ petal width \n",
    "* $P(x) =$ estimate of the probability that the plant is a virginica.\n",
    "<br><br>\n",
    "$$0\\leq P(x) \\leq 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Sigmoid function\n",
    "<br><br>\n",
    "$$ \\sigma : x \\mapsto  \\frac{1}{1+e^{-x}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = np.arange(-5, 5, .01)\n",
    "fig, ax = plt.subplots(figsize=(15,8))\n",
    "plt.plot( x , sigmoid(x) , 'r--' , label='sigmoid' );  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,8))\n",
    "iris.groupby('isVirginica').hist(column='petal_width' , normed=True , ax=ax)\n",
    "plt.legend(['not virginca', 'virginica'])\n",
    "plt.plot(x, sigmoid(x) , 'r--' );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<font size=6>\n",
    "**Logistic Regression** is a model depending on **parameters**:  **W** and **B**.  \n",
    "    <br>\n",
    "For an **input x** it  ouputs the probability\n",
    "<br><br>\n",
    "$$P_{W,B}(x) = \\sigma(Wx+B)$$\n",
    "where     \n",
    "$$ \\sigma : x \\mapsto  \\frac{1}{1+e^{-x}}$$\n",
    "is the **sigmoid function **.   \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.2 Logistic Regression with Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model.fit( iris[['petal_width']] , iris['isVirginica'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "w , b = model.coef_ , model.intercept_\n",
    "print(w,b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "petal_widths = np.arange(0,3,0.01)\n",
    "predicted_proba = model.predict_proba(petal_widths.reshape(-1,1))[:,1]\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(petal_widths, predicted_proba, 'r--')\n",
    "plt.xlabel('petal_width')\n",
    "plt.ylabel('predicted probability');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(13,8))\n",
    "iris.groupby('isVirginica').hist(column='petal_width', normed=True, ax=ax, alpha=.8)\n",
    "plt.legend(['not virginca', 'virginica'])\n",
    "plt.plot(petal_widths, predicted_proba,'r--');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### How to evaluate the model?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<font size=6>\n",
    "$$ \\textbf{Accuracy} = \\frac{\\text{number of samples correctly classified}}{\\text{total number of samples}}$$\n",
    "<size>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model.score( iris[['petal_width']] , iris['isVirginica'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1.3 Logistic Regression with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Graphical representation of Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Choose the parameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* W \n",
    "* B "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![logistic regression](../figures/img/01-log.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![logistic regression](../figures/img/01-log.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential( [\n",
    "    Dense(1, input_dim=1), # for the map x -> W*x + B\n",
    "    Activation('sigmoid') # for the sigmoid function\n",
    "]  ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='binary_crossentropy' , metrics=['acc'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model.fit( iris[['petal_width']] , iris['isVirginica'] , epochs=500 , verbose=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model.get_weights() # get the paramters W and B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model.evaluate( iris[['petal_width']] , iris['isVirginica'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,8))\n",
    "iris.groupby('isVirginica').hist(column='petal_width', normed=True, ax=ax)\n",
    "plt.legend(['not virginica', 'virginica'])\n",
    "predicted_proba = model.predict(petal_widths.reshape(-1,1))[:,0]\n",
    "plt.plot(petal_widths, predicted_proba,'r--');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Part 2\n",
    "# Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## How does Logistic Regression work? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 2.1 Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(1 , input_dim=1 , kernel_regularizer=regularizers.l2(0.1)) ,\n",
    "    Activation('sigmoid') , \n",
    "]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model.compile( optimizer='sgd' , loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model.fit( iris[['petal_width']] , iris['isVirginica'] , epochs=500 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x_grid, y_grid = np.mgrid[ -10:10:.1 , -10:10:.1 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def get_accuracy( w , b ):\n",
    "    layer =  model.layers[0]\n",
    "    layer.set_weights( [ np.array([[w]]) , np.array( [b] ) ] ) \n",
    "    accuracy = model.evaluate( iris[['petal_width']] , iris[['isVirginica']] , verbose=0 )[1]\n",
    "    return accuracy\n",
    "vectorize_accuracy = np.vectorize(get_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#acc_grid  = vectorize_accuracy( x_grid , y_grid )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig , ax = plt.subplots(figsize=(15,7))\n",
    "plt.pcolormesh(x_grid , y_grid , acc_grid , cmap='RdBu_r')\n",
    "plt.colorbar()\n",
    "ax.set(title='Accuracy', xlabel='W', ylabel='B');\n",
    "# model.layers[0].set_weights( [ np.array([[-9]]) , np.array([-9]) ] ) \n",
    "# for i in range(20):\n",
    "#     old_w , old_b = model.get_weights()[0][0][0], model.get_weights()[1][0]\n",
    "#     model.fit( iris[['petal_width']] , iris['isVirginica'] , epochs=30 , verbose=0 )\n",
    "#     new_w , new_b = model.get_weights()[0][0][0] , model.get_weights()[1][0]\n",
    "#     plt.plot([old_w , new_w] , [old_b ,new_b] , 'kX--' , markersize=8 ,linewidth=2 )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Problem: the accuracy is constant on huge zones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 2.2 Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<font size=6>\n",
    "$$\\text{Loss} := -\\frac{1}{n}\\sum_{i=1}^n y_i \\log(p_i) + (1-y_i)\\log(1-p_i)$$\n",
    "</font>\n",
    "\n",
    "* <font size=6>n = number of samples</font>\n",
    "*  <font size=6>$y_i\\in \\{0,1\\}$ is the class (=species) of the i-th sample</font>\n",
    "\n",
    "*  <font size=6>$p_i \\in [0,1]$ is the predicted probability $P(x_i)$ calculated by the model</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If $y=1$ \n",
    "$$ -\\big(y \\log(p) + (1-y)\\log(1-p)\\big)  = -\\log(p)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If $y=0$ \n",
    "$$ -\\big(y \\log(p) + (1-y)\\log(1-p) \\big)  =  -\\log(1-p)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "probas = np.arange(0,1,.0001)\n",
    "loss = - np.log(probas)\n",
    "plt.figure(figsize=(12,7))\n",
    "plt.plot(probas , loss )\n",
    "plt.xlabel('p=probability')\n",
    "plt.ylabel('Loss = $-\\log(p)$')\n",
    "plt.title('Plot of $p \\mapsto  -\\log(p)$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model.evaluate( iris[['petal_width']] , iris['isVirginica'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def get_loss(weight,bias):\n",
    "    layer =  model.layers[0]\n",
    "    layer.set_weights( [ np.array([[weight]]) , np.array([bias]) ] ) \n",
    "    loss = model.evaluate(iris[['petal_width']], iris[['isVirginica']], verbose=0 )[0]\n",
    "    return loss\n",
    "vloss = np.vectorize(get_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "loss_grid = vloss(x_grid,y_grid)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig , ax_loss = plt.subplots(figsize=(16,7))\n",
    "plt.pcolormesh(x_grid , y_grid , loss_grid  , cmap='RdBu_r')\n",
    "plt.colorbar(); plt.contour(x_grid, y_grid, loss_grid,20)\n",
    "plt.title('Loss function'); plt.xlabel('w'); plt.ylabel('b');\n",
    "# model.layers[0].set_weights( [ np.array([[-9]]) , np.array([-9]) ] ) \n",
    "# for i in range(15):\n",
    "#     old_weight, old_bias = model.get_weights()[0][0][0], model.get_weights()[1][0]\n",
    "#     model.fit(iris[['petal_width']] , iris[['isVirginica']] , epochs=40 , verbose=0 )\n",
    "#     weight, bias = model.get_weights()[0][0][0] , model.get_weights()[1][0]\n",
    "#     plt.plot([old_weight,weight] , [old_bias,bias] , 'kX--' , markersize=14 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Gradient descent\n",
    "* Goal: **minimize** the **loss** of the **model**\n",
    "* Step by step **change** the parameters in a **direction** to **minimize** the **loss**\n",
    "* **Direction**: calculated with **backpropagation** (computes **gradient**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Part 3\n",
    "# Neural Networks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 3.1 Logistic Regression again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Replace the species virginica by versicolor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "iris['isVersicolor'] = (iris['species'] == 'versicolor').apply(int)\n",
    "iris.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,6))\n",
    "iris.groupby('isVersicolor').hist( column='petal_width', ax=ax , bins=15 )\n",
    "plt.legend( [ 'not versicolor' , 'versicolor' ] )\n",
    "plt.xlabel('petal width'); plt.ylabel('number of samples'); plt.title('');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Goal: determine if an iris is a versicolor knowing its petal width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense( 1 , input_dim=1 ) ,\n",
    "    Activation('sigmoid') ,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model.compile( optimizer='sgd' , loss='binary_crossentropy' , metrics=['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model.fit( iris[['petal_width']] , iris['isVersicolor'] , epochs=500 );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,7))\n",
    "iris.groupby('isVersicolor').hist(column='petal_width', normed=True, ax=ax)\n",
    "plt.legend(['not versicolor', 'versicolor'])\n",
    "predicted_proba = model.predict(petal_widths.reshape(-1,1))[:,0]\n",
    "plt.plot(petal_widths, predicted_proba  ,'r--' )\n",
    "plt.hlines(0.5, *ax.get_xlim(), linestyles='dotted');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<font size=8><center> We want</center></font>| <font size=8><center>We don't want</center> </font>\n",
    "--------|-----------\n",
    "![non monotonic curve](../figures/img/graph_nn.png) | ![monotonic curve](../figures/img/graph_logistic.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<font size=7>**BAD NEWS**: PREDICTED PROBABILITIES BY LOGISTIC REGRESSION CAN NOT GO UP AND DOWN</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 3.2 Neural networks with hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![NN](../figures/img/01-log.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![NN](../figures/img/nn_color.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![NN](../figures/img/nn_color.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential( [\n",
    "Dense( 3 , input_dim=1 ) , \n",
    "Activation('sigmoid') ,\n",
    "Dense(1) ,\n",
    "Activation('sigmoid')\n",
    "] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.SGD(lr=.1), loss='binary_crossentropy', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.subplots(nrows=2  , ncols=3 , figsize=(18,8) , sharex=True , sharey=True)\n",
    "for i in range(1,7):\n",
    "    plt.subplot(2 , 3 , i)\n",
    "    model.fit( iris[['petal_width']] , iris['isVersicolor'] , epochs=300 , verbose=0 )\n",
    "    probas = model.predict(petal_widths.reshape(-1,1))[:,0]\n",
    "    plt.plot( petal_widths , probas , 'r--' , label='{} epochs'.format(i*300))\n",
    "    plt.ylim((0,1))\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model.evaluate( iris[['petal_width']] , iris['isVersicolor'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,7))\n",
    "iris.groupby('isVersicolor').hist(column='petal_width' , normed=True , ax=ax)\n",
    "plt.legend(['not versicolor', 'versicolor'])\n",
    "predicted_proba = model.predict(petal_widths.reshape(-1,1))[:,0]\n",
    "plt.plot(petal_widths , predicted_proba , 'r--');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Neural Networks are **models** depending on **parameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **Logistic Regression**: the simplest neural network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Neural Networks are made of **layers**. More layers = more expressivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Behind the hood: **fit** the **parameters** with the **data** to **minimize** the **loss**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **Keras**: easy interface to use Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center>Thank you for your attention</center>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
